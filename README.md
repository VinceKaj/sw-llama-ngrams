# sw-llama-ngrams
This repository offers scripts and documentation for how to fine tune an LLM (Llama-3-8B-Instruct) on switchboard data using LoRa adapters. The fine-tuned models is used to generate conversations in the style of switchboard and training ngram models to evaluate their perplexity.
